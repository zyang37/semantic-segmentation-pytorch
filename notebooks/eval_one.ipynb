{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "medical-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libs\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from distutils.version import LooseVersion\n",
    "# Numerical libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.io import loadmat\n",
    "# Our libs\n",
    "from mit_semseg.config import cfg\n",
    "from mit_semseg.dataset import ValDataset\n",
    "from mit_semseg.models import ModelBuilder, SegmentationModule\n",
    "from mit_semseg.utils import AverageMeter, colorEncode, accuracy, intersectionAndUnion, setup_logger\n",
    "from mit_semseg.lib.nn import user_scattered_collate, async_copy_to\n",
    "from mit_semseg.lib.utils import as_numpy\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys, csv, torch, numpy, scipy.io, PIL.Image, torchvision.transforms\n",
    "\n",
    "sys.path.insert(1, '/home/zyang/Documents/Noisey-image')\n",
    "\n",
    "from noise_video_gen import *\n",
    "\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rational-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import yaml\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##################### model stuff #####################\n",
    "# System libs\n",
    "import csv, torch, scipy.io, PIL.Image, torchvision.transforms\n",
    "# Our libs\n",
    "from mit_semseg.config import cfg\n",
    "from mit_semseg.utils import colorEncode\n",
    "from mit_semseg.dataset import ValDataset\n",
    "from mit_semseg.lib.utils import as_numpy\n",
    "from mit_semseg.models import ModelBuilder, SegmentationModule\n",
    "from mit_semseg.lib.nn import user_scattered_collate, async_copy_to\n",
    "from mit_semseg.utils import AverageMeter, colorEncode, accuracy, intersectionAndUnion, setup_logger\n",
    "\n",
    "# pass in mode config(yaml file)\n",
    "# return a dict for the file \n",
    "# return decoder and encoder weights path\n",
    "def parse_model_config(path):\n",
    "    with open(path) as file:\n",
    "        data = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    \n",
    "    encoder_path = None\n",
    "    decoder_path = None\n",
    "\n",
    "    for p in os.listdir(data['DIR']):\n",
    "        if \"encoder\" in p.lower():\n",
    "            encoder_path = \"{}/{}\".format(data['DIR'], p)\n",
    "            continue\n",
    "        if \"decoder\" in p.lower():\n",
    "            decoder_path = \"{}/{}\".format(data['DIR'], p)\n",
    "            continue\n",
    "\n",
    "    if encoder_path==None or decoder_path==None:\n",
    "        raise(\"model weights not found\")\n",
    "        \n",
    "    return data, encoder_path, decoder_path\n",
    "\n",
    "def visualize_result(img, pred, index=None):\n",
    "    # filter prediction class if requested\n",
    "    if index is not None:\n",
    "        pred = pred.copy()\n",
    "        pred[pred != index] = -1\n",
    "        print(f'{names[index+1]}:')\n",
    "\n",
    "    # colorize prediction\n",
    "    pred_color = colorEncode(pred, colors).astype(numpy.uint8)\n",
    "\n",
    "    # aggregate images and save\n",
    "    im_vis = numpy.concatenate((img, pred_color), axis=1)\n",
    "    #if show==True:\n",
    "        #display(PIL.Image.fromarray(im_vis))\n",
    "    #else:\n",
    "    return pred_color, im_vis\n",
    "\n",
    "def process_img(path=None, frame=None):\n",
    "    # Load and normalize one image as a singleton tensor batch\n",
    "    pil_to_tensor = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], # These are RGB mean+std values\n",
    "            std=[0.229, 0.224, 0.225])  # across a large photo dataset.\n",
    "    ])\n",
    "    # pil_image = PIL.Image.open('../ADE_val_00001519.jpg').convert('RGB')\n",
    "    if path!=None:\n",
    "        pil_image = PIL.Image.open(path).convert('RGB')\n",
    "    else:\n",
    "        pil_image = PIL.Image.fromarray(frame)\n",
    "\n",
    "    img_original = numpy.array(pil_image)\n",
    "    img_data = pil_to_tensor(pil_image)\n",
    "    singleton_batch = {'img_data': img_data[None].cuda()}\n",
    "    output_size = img_data.shape[1:]\n",
    "    return (img_original, singleton_batch, output_size)\n",
    "\n",
    "def predict_img(segmentation_module, singleton_batch, output_size):\n",
    "    # Run the segmentation at the highest resolution.\n",
    "    with torch.no_grad():\n",
    "        scores = segmentation_module(singleton_batch, segSize=output_size)\n",
    "\n",
    "    # Get the predicted scores for each pixel\n",
    "    _, pred = torch.max(scores, dim=1)\n",
    "    pred = pred.cpu()[0].numpy()\n",
    "    return pred\n",
    "\n",
    "\n",
    "def get_color_palette(pred, bar_height):\n",
    "\n",
    "    pred = np.int32(pred)\n",
    "    pixs = pred.size\n",
    "\n",
    "    top_left_y = 0\n",
    "    bottom_right_y = 30\n",
    "    uniques, counts = np.unique(pred, return_counts=True)\n",
    "\n",
    "    # Create a black image\n",
    "    # bar_height = im_vis.shape[0]\n",
    "    img = np.zeros((bar_height,250,3), np.uint8)\n",
    "\n",
    "    for idx in np.argsort(counts)[::-1]:\n",
    "        color_index = uniques[idx]\n",
    "        name = names[color_index + 1]\n",
    "        ratio = counts[idx] / pixs * 100\n",
    "        if ratio > 0.1:\n",
    "            print(\"{}  {}: {:.2f}% {}\".format(color_index+1, name, ratio, colors[color_index]))\n",
    "            img = cv2.rectangle(img, (0,top_left_y), (250,bottom_right_y), \n",
    "                       (int(colors[color_index][0]),int(colors[color_index][1]),int(colors[color_index][2])), -1)\n",
    "            img = cv2.putText(img, \"{}: {:.3f}%\".format(name, ratio), (0,top_left_y+20), 5, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            top_left_y+=30\n",
    "            bottom_right_y+=30\n",
    "            \n",
    "    return img\n",
    "\n",
    "\n",
    "def transparent_overlays(image, annotation, alpha=0.5):\n",
    "    img1 = image.copy()\n",
    "    img2 = annotation.copy()\n",
    "\n",
    "    # I want to put logo on top-left corner, So I create a ROI\n",
    "    rows,cols,channels = img2.shape\n",
    "    roi = img1[0:rows, 0:cols ]\n",
    "\n",
    "    # Now create a mask of logo and create its inverse mask also\n",
    "    img2gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Now black-out the area of logo in ROI\n",
    "    # img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "\n",
    "    # Take only region of logo from logo image.\n",
    "    img2_fg = cv2.bitwise_and(img2,img2,mask = mask)\n",
    "\n",
    "    # Put logo in ROI and modify the main image\n",
    "    # dst = cv2.add(img1_bg, img2_fg)\n",
    "    dst = cv2.addWeighted(image.copy(), 1-alpha, img2_fg, alpha, 0)\n",
    "    img1[0:rows, 0:cols ] = dst\n",
    "    return dst\n",
    "\n",
    "\n",
    "def evaluate(segmentation_module, loader, cfg, gpu):\n",
    "    acc_meter = AverageMeter()\n",
    "    intersection_meter = AverageMeter()\n",
    "    union_meter = AverageMeter()\n",
    "    time_meter = AverageMeter()\n",
    "\n",
    "    segmentation_module.eval()\n",
    "\n",
    "    pbar = tqdm(total=len(loader), leave=False)\n",
    "    for batch_data in loader:\n",
    "        # process data\n",
    "        batch_data = batch_data[0]\n",
    "        seg_label = as_numpy(batch_data['seg_label'][0])\n",
    "        img_resized_list = batch_data['img_data']\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        tic = time.perf_counter()\n",
    "        with torch.no_grad():\n",
    "            segSize = (seg_label.shape[0], seg_label.shape[1])\n",
    "            scores = torch.zeros(1, cfg.DATASET.num_class, segSize[0], segSize[1])\n",
    "            scores = async_copy_to(scores, gpu)\n",
    "\n",
    "            for img in img_resized_list:\n",
    "                feed_dict = batch_data.copy()\n",
    "                feed_dict['img_data'] = img\n",
    "                del feed_dict['img_ori']\n",
    "                del feed_dict['info']\n",
    "                feed_dict = async_copy_to(feed_dict, gpu)\n",
    "\n",
    "                # forward pass\n",
    "                scores_tmp = segmentation_module(feed_dict, segSize=segSize)\n",
    "                scores = scores + scores_tmp / len(cfg.DATASET.imgSizes)\n",
    "\n",
    "            _, pred = torch.max(scores, dim=1)\n",
    "            pred = as_numpy(pred.squeeze(0).cpu())\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        time_meter.update(time.perf_counter() - tic)\n",
    "\n",
    "        # calculate accuracy\n",
    "        acc, pix = accuracy(pred, seg_label)\n",
    "        intersection, union = intersectionAndUnion(pred, seg_label, cfg.DATASET.num_class)\n",
    "        acc_meter.update(acc, pix)\n",
    "        intersection_meter.update(intersection)\n",
    "        union_meter.update(union)\n",
    "\n",
    "        # visualization\n",
    "        if cfg.VAL.visualize:\n",
    "            visualize_result(\n",
    "                (batch_data['img_ori'], seg_label, batch_data['info']),\n",
    "                pred,\n",
    "                os.path.join(cfg.DIR, 'result')\n",
    "            )\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    # summary\n",
    "    iou = intersection_meter.sum / (union_meter.sum + 1e-10)\n",
    "    #for i, _iou in enumerate(iou):\n",
    "        #print('class [{}], IoU: {:.4f}'.format(i, _iou))\n",
    "\n",
    "    #print('[Eval Summary]:')\n",
    "    #print('Mean IoU: {:.4f}, Accuracy: {:.2f}%, Inference Time: {:.4f}s'\n",
    "    #      .format(iou.mean(), acc_meter.average()*100, time_meter.average()))\n",
    "    \n",
    "    return pred, acc_meter.average()*100\n",
    "\n",
    "\n",
    "# create a tmp_obgt for 1 img\n",
    "def create_tmp_obgt(img_path, anno_path, width, height, tmp_path=\"tmp_results/tmp_eval.odgt\"):\n",
    "    eval_img = \"{\\\"fpath_img\\\": \" + \"\\\"{}\\\", \".format(img_path) + \"\\\"fpath_segm\\\": \" + \"\\\"{}\\\", \".format(anno_path) + \\\n",
    "                \"\\\"width\\\": \" + str(width) + \", \\\"height\\\": \" + str(height) + \"}\"\n",
    "    f = open(tmp_path, \"w\")\n",
    "    f.write(\"{}\".format(eval_img))\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "def setup_oneImg_loader(img_path, anno_path, tmp_path=\"tmp_results/tmp_eval.odgt\", update=0):\n",
    "    img = PIL.Image.open(img_path).convert('RGB')\n",
    "    anno_rgb = PIL.Image.open(anno_path).convert('RGB')\n",
    "    anno = PIL.Image.open(anno_path)\n",
    "    anno = np.array(anno)\n",
    "    anno[np.where(anno!=0)]-=1\n",
    "\n",
    "    width = img.size[0]\n",
    "    height = img.size[1]\n",
    "    # im_vis = numpy.concatenate((img, anno_rgb), axis=1)\n",
    "    # display(PIL.Image.fromarray(im_vis))\n",
    "    if update==0:\n",
    "        create_tmp_obgt(img_path, anno_path, width, height, tmp_path=tmp_path)\n",
    "    \n",
    "    # Dataset and Loader\n",
    "    dataset_val = ValDataset(\"\", tmp_path, cfg.DATASET)\n",
    "    loader_val = torch.utils.data.DataLoader(\n",
    "        dataset_val,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        collate_fn=user_scattered_collate,\n",
    "        num_workers=1,\n",
    "        drop_last=True)\n",
    "    \n",
    "    return loader_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "trained-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/home/zyang/Documents/fork_sseg_mit/notebooks/data/ADEChallengeData2016/images/training/ADE_train_00000001.jpg\"\n",
    "anno_path = \"/home/zyang/Documents/fork_sseg_mit/notebooks/data/ADEChallengeData2016/annotations/training/ADE_train_00000001.png\"\n",
    "\n",
    "tmp_img_path = '../tmp_results/tmp.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "composite-frost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "anno = PIL.Image.open(anno_path)\n",
    "anno = np.array(anno)\n",
    "anno[np.where(anno!=0)]-=1\n",
    "\n",
    "'''\n",
    "img = PIL.Image.open(img_path).convert('RGB')\n",
    "anno_rgb = PIL.Image.open(anno_path).convert('RGB')\n",
    "\n",
    "width = img.size[0]\n",
    "height = img.size[1]\n",
    "\n",
    "im_vis = numpy.concatenate((img, anno_rgb), axis=1)\n",
    "display(PIL.Image.fromarray(im_vis))\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lined-helicopter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Dataset and Loader\n",
    "dataset_val = ValDataset(\"\", \"tmp_eval.odgt\", cfg.DATASET)\n",
    "loader_val = torch.utils.data.DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=user_scattered_collate,\n",
    "    num_workers=1,\n",
    "    drop_last=True)\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "brief-netscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing config/ade20k-resnet50dilated-ppm_deepsup.yaml\n",
      "Loading weights for net_encoder\n",
      "Loading weights for net_decoder\n",
      "\n",
      "Evaluation on\n",
      "Images: /home/zyang/Documents/fork_sseg_mit/notebooks/data/ADEChallengeData2016/images/training/ADE_train_00000001.jpg\n",
      "Annotation: /home/zyang/Documents/fork_sseg_mit/notebooks/data/ADEChallengeData2016/images/training/ADE_train_00000001.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# colors\n",
    "colors = scipy.io.loadmat('data/color150.mat')['colors']\n",
    "names = {}\n",
    "with open('data/object150_info.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        names[int(row[0])] = row[5].split(\";\")[0]\n",
    "\n",
    "# parse cfg\n",
    "cfg.merge_from_file(\"config/ade20k-resnet50dilated-ppm_deepsup.yaml\")\n",
    "# cfg.merge_from_list(opts)\n",
    "\n",
    "# Network Builders\n",
    "print(\"parsing {}\".format(\"config/ade20k-resnet50dilated-ppm_deepsup.yaml\"))\n",
    "model_config, encoder_path, decoder_path = parse_model_config(\"config/ade20k-resnet50dilated-ppm_deepsup.yaml\")\n",
    "net_encoder = ModelBuilder.build_encoder(\n",
    "    arch = model_config[\"MODEL\"]['arch_encoder'],\n",
    "    fc_dim = model_config['MODEL']['fc_dim'],\n",
    "    weights = encoder_path)\n",
    "net_decoder = ModelBuilder.build_decoder(\n",
    "    arch = model_config[\"MODEL\"]['arch_decoder'],\n",
    "    fc_dim = model_config['MODEL']['fc_dim'],\n",
    "    num_class = model_config['DATASET']['num_class'],\n",
    "    weights = decoder_path,\n",
    "    use_softmax=True)\n",
    "\n",
    "crit = torch.nn.NLLLoss(ignore_index=-1)\n",
    "segmentation_module = SegmentationModule(net_encoder, net_decoder, crit)\n",
    "# segmentation_module.eval()\n",
    "segmentation_module.cuda()\n",
    "\n",
    "# predict on 1 img\n",
    "print(\"\\nEvaluation on\\nImages: {}\\nAnnotation: {}\\n\".format(img_path, img_path))\n",
    "#img_path = args.img\n",
    "#anno_path = args.anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dried-cargo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../tmp_results/tmp.jpg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "billion-coalition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zyang/Documents/fork_sseg_mit/notebooks/data/ADEChallengeData2016/images/training/ADE_train_00000001.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "assured-shoulder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]/home/zyang/Documents/Noisey-image/noise_video_gen.py:15: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[coords] = 1\n",
      "/home/zyang/Documents/Noisey-image/noise_video_gen.py:20: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[coords] = 0\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "all_amount = []\n",
    "all_acc = []\n",
    "pred_num_class = []\n",
    "\n",
    "# noise\n",
    "copyfile(img_path, tmp_img_path)\n",
    "\n",
    "img = cv2.imread(tmp_img_path)\n",
    "org_img = img.copy()\n",
    "\n",
    "amount = 0.0\n",
    "while(True):\n",
    "    loader_val = setup_oneImg_loader(tmp_img_path, anno_path, tmp_path=\"../tmp_results/tmp_eval.odgt\", update=0)\n",
    "    segmentation_module.cuda()\n",
    "    pred, acc = evaluate(segmentation_module, loader_val, cfg, 0)\n",
    "    \n",
    "    all_amount.append(amount)\n",
    "    all_acc.append(acc)\n",
    "    pred_num_class.append(len(np.unique(pred)))\n",
    "    \n",
    "    amount+=0.0001\n",
    "    frame = saltAndPapper_noise(org_img, s_vs_p=0.5, amount=amount)\n",
    "    \n",
    "    # overwrite tmp.jpg\n",
    "    cv2.imwrite(tmp_img_path, frame)\n",
    "    \n",
    "    count+=1\n",
    "    if count==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unsigned-nursing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[90.93313963631054,\n",
       " 90.46718833757835,\n",
       " 89.37510506900453,\n",
       " 78.77843999885809,\n",
       " 63.714161557273286]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "emotional-cardiff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 12, 12, 12, 12]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "touched-atlas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>PixelAcc</th>\n",
       "      <th>num_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>90.933140</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>90.467188</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002</td>\n",
       "      <td>89.375105</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003</td>\n",
       "      <td>78.778440</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004</td>\n",
       "      <td>63.714162</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount   PixelAcc  num_class\n",
       "0   0.000  90.933140         13\n",
       "1   0.001  90.467188         12\n",
       "2   0.002  89.375105         12\n",
       "3   0.003  78.778440         12\n",
       "4   0.004  63.714162         12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_name = 'tmp'\n",
    "df = pd.DataFrame()\n",
    "df['amount'] = all_amount\n",
    "df['PixelAcc'] = all_acc\n",
    "df['num_class'] = pred_num_class\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "piano-extent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>PixelAcc</th>\n",
       "      <th>num_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>90.933140</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>90.855745</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>90.788184</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>90.740923</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>90.818634</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>90.697151</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0006</td>\n",
       "      <td>90.595967</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0007</td>\n",
       "      <td>90.395821</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>90.402799</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0009</td>\n",
       "      <td>90.251817</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>90.273068</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0011</td>\n",
       "      <td>90.240398</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0012</td>\n",
       "      <td>90.410094</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0013</td>\n",
       "      <td>90.097345</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0014</td>\n",
       "      <td>90.184255</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0015</td>\n",
       "      <td>90.003140</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0016</td>\n",
       "      <td>89.997748</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0017</td>\n",
       "      <td>89.798870</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0018</td>\n",
       "      <td>89.985695</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0019</td>\n",
       "      <td>89.218096</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0020</td>\n",
       "      <td>87.712398</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0021</td>\n",
       "      <td>89.715449</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0022</td>\n",
       "      <td>88.974178</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0023</td>\n",
       "      <td>85.004869</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>87.275311</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0025</td>\n",
       "      <td>79.283723</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0026</td>\n",
       "      <td>87.549045</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0027</td>\n",
       "      <td>79.624701</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0028</td>\n",
       "      <td>79.067400</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0029</td>\n",
       "      <td>77.858273</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0030</td>\n",
       "      <td>81.107562</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0031</td>\n",
       "      <td>74.403446</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.0032</td>\n",
       "      <td>76.544158</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.0033</td>\n",
       "      <td>73.554013</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.0034</td>\n",
       "      <td>76.250757</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.0035</td>\n",
       "      <td>70.473786</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.0036</td>\n",
       "      <td>71.930637</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0037</td>\n",
       "      <td>73.157843</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0038</td>\n",
       "      <td>66.254532</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.0039</td>\n",
       "      <td>67.476028</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.0040</td>\n",
       "      <td>66.250726</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.0041</td>\n",
       "      <td>66.900647</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0042</td>\n",
       "      <td>70.472517</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.0043</td>\n",
       "      <td>62.346123</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.0044</td>\n",
       "      <td>61.830691</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0045</td>\n",
       "      <td>65.037159</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0046</td>\n",
       "      <td>62.193555</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0047</td>\n",
       "      <td>63.234571</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0048</td>\n",
       "      <td>61.092591</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.0049</td>\n",
       "      <td>65.621422</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amount   PixelAcc  num_class\n",
       "0   0.0000  90.933140         13\n",
       "1   0.0001  90.855745         13\n",
       "2   0.0002  90.788184         13\n",
       "3   0.0003  90.740923         12\n",
       "4   0.0004  90.818634         13\n",
       "5   0.0005  90.697151         13\n",
       "6   0.0006  90.595967         13\n",
       "7   0.0007  90.395821         13\n",
       "8   0.0008  90.402799         13\n",
       "9   0.0009  90.251817         13\n",
       "10  0.0010  90.273068         13\n",
       "11  0.0011  90.240398         13\n",
       "12  0.0012  90.410094         12\n",
       "13  0.0013  90.097345         13\n",
       "14  0.0014  90.184255         13\n",
       "15  0.0015  90.003140         13\n",
       "16  0.0016  89.997748         13\n",
       "17  0.0017  89.798870         13\n",
       "18  0.0018  89.985695         12\n",
       "19  0.0019  89.218096         11\n",
       "20  0.0020  87.712398         11\n",
       "21  0.0021  89.715449         12\n",
       "22  0.0022  88.974178         11\n",
       "23  0.0023  85.004869         12\n",
       "24  0.0024  87.275311         12\n",
       "25  0.0025  79.283723         12\n",
       "26  0.0026  87.549045         11\n",
       "27  0.0027  79.624701         11\n",
       "28  0.0028  79.067400         12\n",
       "29  0.0029  77.858273         12\n",
       "30  0.0030  81.107562         12\n",
       "31  0.0031  74.403446         12\n",
       "32  0.0032  76.544158         12\n",
       "33  0.0033  73.554013         12\n",
       "34  0.0034  76.250757         12\n",
       "35  0.0035  70.473786         12\n",
       "36  0.0036  71.930637         12\n",
       "37  0.0037  73.157843         12\n",
       "38  0.0038  66.254532         11\n",
       "39  0.0039  67.476028         11\n",
       "40  0.0040  66.250726         12\n",
       "41  0.0041  66.900647         11\n",
       "42  0.0042  70.472517         10\n",
       "43  0.0043  62.346123         10\n",
       "44  0.0044  61.830691         12\n",
       "45  0.0045  65.037159         13\n",
       "46  0.0046  62.193555         11\n",
       "47  0.0047  63.234571         12\n",
       "48  0.0048  61.092591         12\n",
       "49  0.0049  65.621422         12"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../tmp_results/s_p50.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(PIL.Image.fromarray(pred.astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-freeze",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classes for pred\n",
    "len(np.unique(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(anno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libs\n",
    "import os, csv, torch, numpy, scipy.io, PIL.Image, torchvision.transforms\n",
    "# Our libs\n",
    "from mit_semseg.models import ModelBuilder, SegmentationModule\n",
    "from mit_semseg.utils import colorEncode\n",
    "\n",
    "colors = scipy.io.loadmat('data/color150.mat')['colors']\n",
    "names = {}\n",
    "with open('data/object150_info.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        names[int(row[0])] = row[5].split(\";\")[0]\n",
    "\n",
    "def visualize_result(img, pred, index=None, show=True):\n",
    "    # filter prediction class if requested\n",
    "    if index is not None:\n",
    "        pred = pred.copy()\n",
    "        pred[pred != index] = -1\n",
    "        print(f'{names[index+1]}:')\n",
    "        \n",
    "    # colorize prediction\n",
    "    pred_color = colorEncode(pred, colors).astype(numpy.uint8)\n",
    "\n",
    "    # aggregate images and save\n",
    "    im_vis = numpy.concatenate((img, pred_color), axis=1)\n",
    "    if show==True:\n",
    "        display(PIL.Image.fromarray(im_vis))\n",
    "    else:\n",
    "        return pred_color, im_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_result(img, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_result(img, anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(np.append(np.unique(anno), np.unique(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-pathology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
